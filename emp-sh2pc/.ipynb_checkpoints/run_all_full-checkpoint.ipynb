{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(fileName):\n",
    "    df = pd.read_csv(fileName)   # [1271413 rows x 1 columns]\n",
    "    df = df.to_numpy().flatten()\n",
    "    df = df.tolist()\n",
    "    for i in range(3):\n",
    "        df.extend(df)\n",
    "    return df\n",
    "    \n",
    "def nonNegative(value):\n",
    "    return [int(round(v)) if v>0 else 0 for v in value]\n",
    "\n",
    "def DPTreeH(DPAllNodes, gap):\n",
    "    height = int(math.log(gap, 2)) + 1 #the height of the tree\n",
    "    if height == 1:\n",
    "        return DPAllNodes[0]\n",
    "    succ = DPAllNodes[0: gap].copy() #leaf nodes\n",
    "    pt = 0+gap #the index of the first node in the second level\n",
    "    for i in range(2, height+1, 1): #the level in the paper\n",
    "        gap = int(gap/2) #the number of nodes in this level\n",
    "        succ_new = [0 for i in range(gap)] #compute the sum of succ for each node in this level\n",
    "\n",
    "        for j in range(gap): #\n",
    "            succ_new[j] = succ[j*2] + succ[j*2+1]\n",
    "      \n",
    "        now = DPAllNodes[pt: pt + gap].copy() #the dp nodes for this level\n",
    "\n",
    "        consist = [0 for i in range(gap)] #compute the #z[v] in paper\n",
    "        a = (pow(2, i) - pow(2, i-1)) / (pow(2, i) - 1)\n",
    "        b = (pow(2, i-1) - 1) / (pow(2, i) - 1)\n",
    "        \n",
    "        for j in range(gap):\n",
    "            consist[j] =  a*now[j] + b*succ_new[j]\n",
    "\n",
    "        pt = pt + gap #point to the first node of the next level \n",
    "        succ = consist # needed for next level \n",
    "    return consist[0]\n",
    "\n",
    "def nodesSubtree(i):\n",
    "    i += 1\n",
    "    j = 1\n",
    "    k = i\n",
    "    rootLeft = i\n",
    "    while (k % 2 == 0):\n",
    "        rootLeft = i - 2**j + 1\n",
    "        k = k / 2\n",
    "        j += 1    \n",
    "    return rootLeft - 1\n",
    "\n",
    "def retrieveNodes(i):\n",
    "    left = nodesSubtree(i)\n",
    "    gap = i - left + 1\n",
    "    height = int(math.log(gap, 2)) + 1\n",
    "    for i in range(height):\n",
    "        print(\"i-----\", i)\n",
    "        inteval = pow(2, i)\n",
    "        print(\"inteval\", inteval)\n",
    "        for j in range(left, right+1, inteval):\n",
    "            print(str(j) + \",\" + str(j+inteval-1))\n",
    "            \n",
    "# sort according to the DP hist of root \n",
    "def computeBin(data, markers, dp):\n",
    "    counter = dp.copy()\n",
    "    size = len(data)\n",
    "    binNum = len(dp)\n",
    "    bins = [binNum] * size\n",
    "    # real records \n",
    "    for i in range(size):\n",
    "        bin_num = data[i] - 1\n",
    "        if markers[i] == 1:  \n",
    "            if counter[bin_num] > 0:\n",
    "                bins[i] = bin_num\n",
    "                counter[bin_num] = counter[bin_num] - 1\n",
    "    # dummy records \n",
    "    for i in range(size):\n",
    "        if markers[i] == 2:\n",
    "            for j in range(binNum):\n",
    "                if bins[i] == binNum and counter[j] > 0 :\n",
    "                    bins[i] = j\n",
    "                    counter[j] = counter[j] - 1\n",
    "    return bins\n",
    "\n",
    "# sort according to the DP hist of root \n",
    "def computeBinJ(data, markers, sortDPd, j):\n",
    "    counter = sortDPd\n",
    "    size = len(data)\n",
    "    bins = [1] * size\n",
    "    # real records \n",
    "    for i in range(size):\n",
    "        bin_num = data[i] - 1\n",
    "        if markers[i] == 1 and bin_num == j and counter > 0:\n",
    "            bins[i] = 0\n",
    "            counter = counter - 1\n",
    "    # dummy records \n",
    "    for i in range(size):\n",
    "        if markers[i] == 2 and counter > 0:\n",
    "            bins[i] = 0\n",
    "            counter = counter - 1\n",
    "            continue\n",
    "    return bins\n",
    "\n",
    "\n",
    "\n",
    "# using list comprehension + sum() + list slicing\n",
    "# prefix sum list\n",
    "def computePrefix(test_list):\n",
    "    res = [sum(test_list[ : i + 1]) for i in range(len(test_list))]\n",
    "    return res\n",
    "    \n",
    "def seperateD(dpMergedPrevious, dataMergedPrevious, d, numBin):\n",
    "    vectFirst = [None] * numBin\n",
    "    vectSecond = []\n",
    "    intervals = len(dpMergedPrevious)\n",
    "    # preprocess preefix --> cut last bin if no enough records \n",
    "    # preprocess prefixsum\n",
    "    dpHistPrefixIntrevals = [None] * intervals\n",
    "    for i in range(intervals):  # for each interval\n",
    "        sizeInterval = len(dataMergedPrevious[i])\n",
    "        dpMergedPrevious[i][numBin-1] = sizeInterval #?\n",
    "        dpHistPrefix = [0] * (numBin+1) \n",
    "        for j in range(numBin):\n",
    "            dpHistPrefix[j+1] = dpMergedPrevious[i][j]\n",
    "        dpHistPrefixIntrevals[i] = dpHistPrefix\n",
    "    for i in range(numBin): # for each bin \n",
    "        first = []\n",
    "        for j in range(intervals):  # for each interval\n",
    "            left = dpHistPrefixIntrevals[j][i+1] - d if (dpHistPrefixIntrevals[j][i] < dpHistPrefixIntrevals[j][i+1] - d) else dpHistPrefixIntrevals[j][i]\n",
    "            begining = dataMergedPrevious[j][dpHistPrefixIntrevals[j][i]: left].copy()\n",
    "            ending = dataMergedPrevious[j][left: dpHistPrefixIntrevals[j][i+1]].copy()\n",
    "            first.extend(begining)  # the first n-d\n",
    "            vectSecond.extend(ending)   # the last d \n",
    "        vectFirst[i] = first.copy()\n",
    "\n",
    "    return (vectFirst, vectSecond)  \n",
    "\n",
    "def seperateBin(sorted_data, sortDPdHist):\n",
    "    numBin = len(sortDPdHist)\n",
    "    seperatedData = [None]*numBin\n",
    "    dpHistPrefix_tmp = computePrefix(sortDPdHist)\n",
    "    dpHistPrefix_tmp[numBin-1] = len(sorted_data)  \n",
    "    dpHistPrefix = [0]*(numBin+1)\n",
    "    for j in range(numBin):\n",
    "        dpHistPrefix[j+1] = dpHistPrefix_tmp[j]\n",
    "    for j in range(numBin):\n",
    "        seperatedData[j] = sorted_data[dpHistPrefix[j]: dpHistPrefix[j+1]].copy()\n",
    "\n",
    "    return seperatedData \n",
    "\n",
    "\n",
    "# for each time unit, insert real and dummy records, and compute true histogram\n",
    "def originalDataMarkerHistsTree(T, numReal, num_Dummy, numBins, df):\n",
    "    originalData = {}\n",
    "    originalDummyMarkers = {}\n",
    "    trueHists = [None] * T\n",
    "    for i in range(T):\n",
    "        numDummy = num_Dummy\n",
    "        if (i%2 == 1):\n",
    "            numDummy = 0\n",
    "        # for originalData\n",
    "        records = [None] * (numReal+numDummy)\n",
    "        records[0: numReal] = df[i*numReal: (i+1)*numReal].copy()\n",
    "        records[numReal: numReal+numDummy] = [10] * numDummy #todo change mpc code\n",
    "        originalData[i] = records\n",
    "        # for originalDummyMarker\n",
    "        DummyMarker = [None] * (numReal+numDummy)\n",
    "        DummyMarker[0: numReal] = [1] * numReal\n",
    "        DummyMarker[numReal: numReal+numDummy] = [2] * numDummy #todo change mpc code\n",
    "        originalDummyMarkers[i] = DummyMarker\n",
    "        # compute trueHists\n",
    "        counts, bins = np.histogram(records, bins=np.arange(1,numBins+2)) #[1,2,3,4,5] -> 4bins\n",
    "        trueHists[i] = counts \n",
    " #   print(originalData)\n",
    " #   print(originalDummyMarkers)\n",
    " #   print(trueHists)\n",
    "    return originalData, originalDummyMarkers, trueHists\n",
    "\n",
    "def originalDataMarkerHistsLeaf(p, eps, T, numReal, numBins, df):\n",
    "    originalData = {}\n",
    "    originalDummyMarkers = {}\n",
    "    trueHists = [None] * T\n",
    "    dummy_leaf = 0\n",
    "    t_ = math.log((1/p), math.e)\n",
    "    b = 1/eps\n",
    "    for i in range(T):\n",
    "        a = round(2*b*math.sqrt((i+1)*math.log((1/p), math.e)))\n",
    "        if (a > i*b):\n",
    "            numDummy = round((1/eps) * t_) * numBins\n",
    "        else:\n",
    "            numDummy = round(a*numBins-dummy_leaf) if round(a*numBins-dummy_leaf) >= 0 else 0 \n",
    "        dummy_leaf += numDummy\n",
    "        \n",
    "        # for originalData\n",
    "        records = [None] * (numReal+numDummy)\n",
    "        records[0: numReal] = df[i*numReal: (i+1)*numReal].copy()\n",
    "        records[numReal: numReal+numDummy] = [10] * numDummy #todo change mpc code\n",
    "        originalData[i] = records\n",
    "        # for originalDummyMarker\n",
    "        DummyMarker = [None] * (numReal+numDummy)\n",
    "        DummyMarker[0: numReal] = [1] * numReal\n",
    "        DummyMarker[numReal: numReal+numDummy] = [2] * numDummy #todo change mpc code\n",
    "        originalDummyMarkers[i] = DummyMarker\n",
    "        # compute trueHists\n",
    "        counts, bins = np.histogram(records, bins=np.arange(1,numBins+2)) #[1,2,3,4,5] -> 4bins\n",
    "        trueHists[i] = counts \n",
    " #   print(originalData)\n",
    " #   print(originalDummyMarkers)\n",
    " #   print(trueHists)\n",
    "    return originalData, originalDummyMarkers, trueHists\n",
    "    \n",
    "def computeTrueRecords(dpHist, dpStore):\n",
    "    binNum = len(dpHist)\n",
    "    recordNum = len(dpStore) \n",
    "            \n",
    "    dpHistPrefix_tmp = computePrefix(dpHist)\n",
    "    dpHistPrefix_tmp[binNum-1] = recordNum  \n",
    "    dpHistPrefix = [0]*(binNum+1)\n",
    "    for j in range(binNum):\n",
    "        dpHistPrefix[j+1] = dpHistPrefix_tmp[j]\n",
    "    trueR = [0]*binNum\n",
    "    for i in range(binNum):\n",
    "        num = 0\n",
    "        for j in range(dpHistPrefix[i], dpHistPrefix[i+1], 1):\n",
    "            if ((dpStore[j]-1) == i): #dpStorePublic[j]: 1122334455\n",
    "                num = num+1\n",
    "        trueR[i] = num\n",
    "    return trueR \n",
    "\n",
    "def computeDummyRecordsCache(cache):\n",
    "    num = 0\n",
    "    size = len(cache)\n",
    "    for i in range(size):\n",
    "        if cache[i] == 2:\n",
    "            num = num+1\n",
    "    return num \n",
    "\n",
    "def intervalRangeQ(i):  \n",
    "    intervalss = []\n",
    "    rightI = i\n",
    "    while (rightI >= 0):\n",
    "        rootLeftI = nodesSubtree(rightI)\n",
    "        intervalRootDPI = str(rootLeftI) + ',' + str(rightI)\n",
    "        intervalss.append(intervalRootDPI)\n",
    "        rightI = rootLeftI - 1\n",
    "    return intervalss\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3%2 == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2: dpHistGen for the root of the subtree\n",
    "def DPTimeTree(T, trueHists, eps, numBins):\n",
    "    dpHists = {}\n",
    "    inconsistDPHists = {}\n",
    "    \n",
    "    for i in range(T):\n",
    "      #  print(str(i)+\"********************************\")\n",
    "        # step2.1 and step2.2: generate DP hists of nodes on the current path (current leaf to root)\n",
    "        rootLeft = nodesSubtree(i)\n",
    "        gap = i - rootLeft + 1\n",
    "       # print(\"rootLeft\", rootLeft)\n",
    "       # print(\"gap\", gap)\n",
    "\n",
    "        while ((gap / 2 >= 1) or (gap >= 1)):\n",
    "            # step2.1: true hists of nodes on the path\n",
    "            trueHistgrams = [0 for j in range(numBins)]\n",
    "            for j in range(rootLeft, (i + 1)): \n",
    "                trueHistgrams += trueHists[j]\n",
    "            # step2.2: DP hists of nodes on the path  \n",
    "           # dpNode = trueHistgrams + 2#np.random.laplace(0, 1 / epsTree, 1)[0]\n",
    "            dpNode = trueHistgrams + np.random.laplace(0, (1/eps), numBins)\n",
    "            dpNode = np.array([float(round(e)) for e in dpNode])\n",
    "            intervalDP = str(rootLeft) + ',' + str(i)\n",
    "          #  print(\"intervalDP\", intervalDP)\n",
    "            inconsistDPHists[intervalDP] = dpNode\n",
    "\n",
    "            rootLeft += int(gap / 2);\n",
    "            gap /= 2;\n",
    "\n",
    "        # step3: compute the consistent DP histogram of the root of the subtree\n",
    "        # step3.1: DP hists of all nodes in the subtree\n",
    "\n",
    "        dpAllNodes = []\n",
    "        rootLeftAgain = nodesSubtree(i)\n",
    "        gapAgain = i - rootLeftAgain + 1\n",
    "        height = int(math.log(gapAgain, 2)) + 1\n",
    "        for j in range(height):\n",
    "          #  print(\"j-----\", j)\n",
    "            inteval = pow(2, j)\n",
    "           # print(\"inteval\", inteval)\n",
    "            for k in range(rootLeftAgain, i+1, inteval):\n",
    "                intervalDP = str(k) + \",\" + str(k+inteval-1)\n",
    "                dpAllNodes.append(inconsistDPHists[intervalDP])\n",
    "        dp = DPTreeH(dpAllNodes, gapAgain)\n",
    "        intervalDP = str(rootLeftAgain) + ',' + str(i)\n",
    "        dpHists[intervalDP] = nonNegative(dp)\n",
    "    return dpHists\n",
    "    #print(trueHists)\n",
    "    #print(dpHists)\n",
    "    #print(inconsistDPHists) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortTree(num_dummy, sortOption, gapAgainThreshold, T, numBins, dpHists, originalData, originalDummyMarkers, eps):\n",
    "    t = math.log((1/0.005), math.e)\n",
    "    d = math.ceil((1/eps) * t)\n",
    "    leftCacheData = []\n",
    "    leftCacheDummyMarker = []\n",
    "    mainData = {}\n",
    "    mainDummyMarker = {}\n",
    "    trueRecordNum = [None] * T\n",
    "    runTimeDPSort = [None] * T\n",
    "    dummyRecordNumCache = [None] * T\n",
    "    \n",
    "    # step4: get the sorted array of the root node \n",
    "    for i in range(T):\n",
    "     #   print(str(i)+\"********************************\")\n",
    "        # step4.1: retrieve the DP histogram of the root node \n",
    "        rootLeftSort = nodesSubtree(i)\n",
    "        intervalRootDP = str(rootLeftSort) + ',' + str(i)\n",
    "        dpRoot = dpHists[intervalRootDP]\n",
    "        gapAgainAgain = i - rootLeftSort + 1\n",
    "        # step4.2: compute the interval of previous nodes\n",
    "        intervalPrevious = []\n",
    "        gapSort = i - rootLeftSort + 1\n",
    "        while ((gapSort / 2 >= 1) or (gapSort >= 1)):\n",
    "            if (rootLeftSort < int(rootLeftSort + (gapSort / 2))):\n",
    "                interval = str(rootLeftSort) + ',' + str(int(rootLeftSort + (gapSort / 2)) - 1)\n",
    "                intervalPrevious.append(interval)\n",
    "            rootLeftSort += int(gapSort / 2);\n",
    "            gapSort /= 2;\n",
    "        #print(intervalPrevious)\n",
    "        # step4.3: get the sorted array of the root node\n",
    "        # option0: if sortOption == 0 or gapAgain <= x\n",
    "        # option1: else if sortOption == 1 \n",
    "        # option2: else sortOption == 2 \n",
    "        \n",
    "        \n",
    "        numDrop = (len(intervalPrevious) - 1) if len(intervalPrevious) > 0 else 0\n",
    "        dropDummy = num_dummy * numDrop\n",
    "       # print(\"dropDummy: \", dropDummy)\n",
    "    \n",
    "        if (sortOption == 0 or gapAgainAgain <= gapAgainThreshold):\n",
    "            dataToSort = leftCacheData.copy()\n",
    "            dummyMarkerToSort = leftCacheDummyMarker.copy();\n",
    "            for interval in intervalPrevious:\n",
    "                dataToSort.extend(mainData[interval])\n",
    "                dummyMarkerToSort.extend(mainDummyMarker[interval])\n",
    "            dataToSort.extend(originalData[i])\n",
    "            dummyMarkerToSort.extend(originalDummyMarkers[i])\n",
    "\n",
    "\n",
    "         #   print(dpRoot)\n",
    "            bins = computeBin(dataToSort,dummyMarkerToSort,dpRoot)\n",
    "            sorted_data = [k for _,k in sorted(zip(bins,dataToSort))]\n",
    "            sorted_marker = [k for _,k in sorted(zip(bins,dummyMarkerToSort))]\n",
    "            totalRecords = sum(dpRoot)\n",
    "            dataToSortSize = len(dataToSort)\n",
    "            sizeDroppedDummy = dataToSortSize - dropDummy\n",
    "            mainData[intervalRootDP] = sorted_data[0:totalRecords].copy()\n",
    "            leftCacheData = sorted_data[totalRecords:sizeDroppedDummy].copy()\n",
    "            mainDummyMarker[intervalRootDP] = sorted_marker[0:totalRecords].copy()\n",
    "            leftCacheDummyMarker = sorted_marker[totalRecords:sizeDroppedDummy].copy()\n",
    "            \n",
    "            #runtime\n",
    "            # 2m(n*#leafs) + O(n*#leafs  * (log(n*#leafs)  ^ 2))\n",
    "            runtimeSortSize = 2*numBins*dataToSortSize + dataToSortSize*math.log(dataToSortSize, math.e)*math.log(dataToSortSize, math.e)\n",
    "            runTimeDPSort[i] = round(runtimeSortSize)\n",
    "           # print(mainData)\n",
    "           # print(leftCacheData)\n",
    "          #  print(mainDummyMarker)\n",
    "          #  print(leftCacheDummyMarker)\n",
    "        else:  # (sortOption == 2)\n",
    "           # print(dpRoot)\n",
    "            dataCache = leftCacheData.copy()\n",
    "            dummyMarkerCache = leftCacheDummyMarker.copy()\n",
    "            dataCache.extend(originalData[i])\n",
    "            dummyMarkerCache.extend(originalDummyMarkers[i])\n",
    "        #    print(\"elsedataCache\", sorted(dataCache))\n",
    "\n",
    "            # retrieve the data and DP histograms of previous nodes in this subtree\n",
    "            # for each bin, we need to put n-d records for each interval together.  \n",
    "            intervalSize = int(len(intervalPrevious))\n",
    "            dataMergedPrevious = [None]*intervalSize\n",
    "            dummyMarkerMergedPrevious = [None]*intervalSize\n",
    "            dpMergedPrevious = [None]*intervalSize\n",
    "            for j in range(intervalSize):\n",
    "                dataMergedPrevious[j] = mainData[intervalPrevious[j]]\n",
    "                dummyMarkerMergedPrevious[j] = mainDummyMarker[intervalPrevious[j]]\n",
    "                dpMergedPrevious[j] = computePrefix(dpHists[intervalPrevious[j]])\n",
    "\n",
    "            encodedRecordsFirst, encodedRecordsSecond = seperateD(dpMergedPrevious, dataMergedPrevious, d, numBins);\n",
    "            dummyMarkerFirst, dummyMarkerSecond = seperateD(dpMergedPrevious, dummyMarkerMergedPrevious, d, numBins);\n",
    "\n",
    "            encodedRecordsSecond.extend(dataCache)\n",
    "            dummyMarkerSecond.extend(dummyMarkerCache)\n",
    "            \n",
    "            sortDPdHist = [None]*numBins\n",
    "            for j in range(numBins):\n",
    "                # sort previous node for each bin and cache--> sorted for this bin + leftCache\n",
    "              #  sizeSort = toSortMergedPrevious.size();\n",
    "                # compute the number of records we need to retrieve;  \n",
    "                # ??? what if the sum of n-d for all intervals is larger than dpRoot[j]? \n",
    "                # d should be not too small!\n",
    "                sortDPd = dpRoot[j]\n",
    "                for k in range(int(len(intervalPrevious))):\n",
    "                    leftAfterCutD = 0 if ((dpHists[intervalPrevious[k]][j] - d) < 0) else (dpHists[intervalPrevious[k]][j] - d);\n",
    "                    sortDPd = sortDPd - leftAfterCutD\n",
    "                sortDPd = 0 if (sortDPd < 0) else sortDPd   # todo: increase d if sortDPd<0\n",
    "         #       print(\"sortDPd\", sortDPd)\n",
    "         #       print(\"toSortMergedPrevious\", sorted(toSortMergedPrevious))\n",
    "                # sort \n",
    "                sortDPdHist[j] = sortDPd\n",
    "           \n",
    "            bins = computeBin(encodedRecordsSecond, dummyMarkerSecond, sortDPdHist)\n",
    "            sorted_data = [k for _,k in sorted(zip(bins,encodedRecordsSecond))]\n",
    "            sorted_marker = [k for _,k in sorted(zip(bins,dummyMarkerSecond))]\n",
    "            \n",
    "            mainData[intervalRootDP] = []\n",
    "            mainDummyMarker[intervalRootDP] = []\n",
    "            \n",
    "            totalRecords = sum(sortDPdHist)\n",
    "            dataToSortSize = len(encodedRecordsSecond)\n",
    "            sizeDroppedDummy = dataToSortSize - dropDummy\n",
    "            \n",
    "            for j in range(numBins):\n",
    "                # n-d\n",
    "                mainData[intervalRootDP].extend(encodedRecordsFirst[j].copy())\n",
    "                mainDummyMarker[intervalRootDP].extend(dummyMarkerFirst[j].copy())\n",
    "                # sorted root d for this bin + left cache\n",
    "                seperatedBinsRecord = seperateBin(sorted_data[0:totalRecords], sortDPdHist)\n",
    "                seperatedBinsDummyMarker = seperateBin(sorted_marker[0:totalRecords], sortDPdHist)\n",
    "                \n",
    "                mainData[intervalRootDP].extend(seperatedBinsRecord[j].copy())\n",
    "                mainDummyMarker[intervalRootDP].extend(seperatedBinsDummyMarker[j].copy())\n",
    "            \n",
    "            leftCacheData = sorted_data[totalRecords:sizeDroppedDummy].copy()\n",
    "            leftCacheDummyMarker = sorted_marker[totalRecords:sizeDroppedDummy].copy()\n",
    "            #runtime\n",
    "            # 2m(n*#leafs) + O(n*#leafs  * (log(n*#leafs)  ^ 2))\n",
    "            runtimeSortSize = 2*numBins*dataToSortSize + dataToSortSize*math.log(dataToSortSize, math.e)*math.log(dataToSortSize, math.e)\n",
    "            runTimeDPSort[i] = round(runtimeSortSize)\n",
    "            \n",
    "          #      print(\"dataCache\", dataCache)\n",
    "         #   print(mainData)\n",
    "         #   print(leftCacheData)\n",
    "         #   print(mainDummyMarker)\n",
    "         #   print(leftCacheDummyMarker)\n",
    "\n",
    "        for interval in intervalPrevious:\n",
    "            mainData.pop(interval, None)\n",
    "            mainDummyMarker.pop(interval, None)\n",
    "        \n",
    "        dummyRecordNumCache[i] = computeDummyRecordsCache(leftCacheDummyMarker)\n",
    "        intervalss = intervalRangeQ(i) \n",
    "      #  print(intervalss)\n",
    "        trueR = np.array([0]*numBins)\n",
    "        for interval in intervalss:\n",
    "            trueR += computeTrueRecords(dpHists[interval], mainData[interval])\n",
    "        trueRecordNum[i] = trueR\n",
    "        \n",
    "    return trueRecordNum, runTimeDPSort, dummyRecordNumCache\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2: dpHistGen for the root of the subtree\n",
    "def DPTimeLeaf(T, trueHists, eps, numBins):\n",
    "    dpHists = {}\n",
    "    for i in range(T):\n",
    "      #  print(str(i)+\"********************************\")\n",
    "        trueHistgrams = trueHists[i]\n",
    "        dp = trueHistgrams + np.random.laplace(0, (1/eps), numBins)\n",
    "        intervalDP = str(i) + ',' + str(i)\n",
    "        dpHists[intervalDP] = nonNegative(dp)\n",
    "    return dpHists\n",
    "    #print(trueHists)\n",
    "    #print(dpHists)\n",
    "    #print(inconsistDPHists) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortLeaf(T, numBins, dpHists, originalData, originalDummyMarkers):\n",
    "    leftCacheData = []\n",
    "    leftCacheDummyMarker = []\n",
    "    mainData = {}\n",
    "    mainDummyMarker = {}\n",
    "    trueRecordNum = [None] * T\n",
    "    runTimeDPSort = [None] * T\n",
    "    dummyRecordNumCache = [None] * T\n",
    "    # step4: get the sorted array of the root node \n",
    "    for i in range(T):\n",
    "      #  print(str(i)+\"********************************\")\n",
    "        dataToSort = leftCacheData.copy()\n",
    "        dummyMarkerToSort = leftCacheDummyMarker.copy()\n",
    "        dataToSort.extend(originalData[i])\n",
    "        dummyMarkerToSort.extend(originalDummyMarkers[i])\n",
    "        \n",
    "        iStr = str(i) + ',' + str(i)\n",
    "        dpH = dpHists[iStr]\n",
    "        bins = computeBin(dataToSort,dummyMarkerToSort,dpH)\n",
    "        sorted_data = [k for _,k in sorted(zip(bins,dataToSort))]\n",
    "        sorted_marker = [k for _,k in sorted(zip(bins,dummyMarkerToSort))]\n",
    "        totalRecords = sum(dpH)\n",
    "        dataToSortSize = len(dataToSort)\n",
    "\n",
    "        mainData[iStr] = sorted_data[0:totalRecords].copy()\n",
    "        leftCacheData = sorted_data[totalRecords:dataToSortSize].copy()\n",
    "        mainDummyMarker[iStr] = sorted_marker[0:totalRecords].copy()\n",
    "        leftCacheDummyMarker = sorted_marker[totalRecords:dataToSortSize].copy()\n",
    "        \n",
    "        runtimeSortSize = 2*numBins*dataToSortSize + dataToSortSize*math.log(dataToSortSize, math.e)*math.log(dataToSortSize, math.e)\n",
    "        runTimeDPSort[i] = round(runtimeSortSize)\n",
    "        dummyRecordNumCache[i] = computeDummyRecordsCache(leftCacheDummyMarker)\n",
    "      #  print(mainData)\n",
    "      #  print(leftCacheData)\n",
    "      #  print(mainDummyMarker)\n",
    "      #  print(leftCacheDummyMarker)\n",
    "        \n",
    "        trueR = np.array([0]*numBins)\n",
    "        for j in range(i+1):\n",
    "            jStr = str(j) + ',' + str(j)\n",
    "            trueR += computeTrueRecords(dpHists[jStr], mainData[jStr])\n",
    "        trueRecordNum[j] = trueR\n",
    "\n",
    "    return trueRecordNum, runTimeDPSort, dummyRecordNumCache\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(treeorLeaf, T, epsAll, numReal, sortOption):\n",
    "    df = readData('nycTaxiData_payment_type.csv')\n",
    "    numBins = 4\n",
    "    p = 0.05\n",
    "    t = math.log((1/p), math.e)\n",
    "    if treeorLeaf == \"tree\":\n",
    "        #tree \n",
    "        level = math.log(T, 2)\n",
    "        eps = epsAll/level  \n",
    "        numDummy = math.ceil((1/eps) * t) * numBins\n",
    "        originalData, originalDummyMarkers, trueHists = originalDataMarkerHistsTree(T, numReal, numDummy, numBins, df)\n",
    "        dpHists = DPTimeTree(T, trueHists, eps, numBins)\n",
    "        gapAgainThreshold = 1 \n",
    "        trueRecordNum, runTimeDPSort, dummyRecordNumCache = sortTree(numDummy, sortOption, gapAgainThreshold, T, numBins, dpHists, originalData, originalDummyMarkers, eps) # original?\n",
    "        #print(trueRecordNum)\n",
    "\n",
    "    else:\n",
    "        #leaf\n",
    "        eps = epsAll\n",
    "        originalData, originalDummyMarkers, trueHists = originalDataMarkerHistsLeaf(p, eps, T, numReal, numBins, df)\n",
    "\n",
    "        dpHistsLeaf = DPTimeLeaf(T, trueHists, eps, numBins)\n",
    "        trueRecordNum, runTimeDPSort, dummyRecordNumCache = sortLeaf(T, numBins, dpHistsLeaf, originalData, originalDummyMarkers)\n",
    "\n",
    "    DPCount = [None]*T\n",
    "    trueCount = [None]*T\n",
    "    for i in range(T):\n",
    "        if (treeorLeaf==\"tree\"):\n",
    "            intervalss = intervalRangeQ(i) \n",
    "            DPI = np.array([0]*numBins)\n",
    "            for interval in intervalss:\n",
    "                DPI += dpHists[interval]\n",
    "            DPCount[i] = DPI\n",
    "        else:\n",
    "            DPI = np.array([0]*numBins)\n",
    "            for j in range(i+1):\n",
    "                DPI += dpHistsLeaf[str(j)+','+str(j)]\n",
    "            DPCount[i] = DPI\n",
    "\n",
    "        trueI = np.array([0]*numBins)\n",
    "        for j in range(i+1):\n",
    "            trueI += trueHists[j]\n",
    "        trueCount[i] = trueI\n",
    "    \n",
    "   # print(\"DPCount: \", DPCount)\n",
    " #   print(\"trueCount: \", trueCount)\n",
    " #   print(\"trueRecordNum: \", trueRecordNum)\n",
    "    \n",
    "    metricDPError = np.sum(np.abs(np.array(DPCount) - np.array(trueCount)), axis =1)\n",
    "    metricDPStoreError = np.sum(np.abs(np.array(DPCount) - np.array(trueRecordNum)), axis =1)\n",
    "    metricTTStoreError = np.sum(np.abs(np.array(trueCount) - np.array(trueRecordNum)), axis =1)\n",
    "    \n",
    "    return metricDPError, metricDPStoreError, metricTTStoreError, runTimeDPSort, dummyRecordNumCache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leaf***************\n",
      "--- 1.750593900680542 seconds ---\n",
      "treeD***************\n",
      "--- 3.505373954772949 seconds ---\n",
      "treeA***************\n",
      "--- 6.165694952011108 seconds ---\n",
      "resulutssss D:  [61.0, 63.0, 113.0, 59.0, 110.0, 107.0, 167.0, 55.0, 114.0, 115.0, 170.0, 119.0, 180.0, 176.0, 241.0, 53.0, 111.0, 113.0, 178.0, 113.0, 176.0, 178.0, 229.0, 110.0, 171.0, 175.0, 231.0, 175.0, 238.0, 236.0, 300.0, 58.0, 103.0, 116.0, 181.0, 124.0, 183.0, 188.0, 252.0, 122.0, 184.0, 188.0, 252.0, 186.0, 250.0, 248.0, 314.0, 123.0, 188.0, 189.0]\n",
      "resulutssss A:  [59.0, 56.0, 118.0, 56.0, 113.0, 116.0, 170.0, 58.0, 111.0, 110.0, 171.0, 120.0, 170.0, 176.0, 234.0, 60.0, 117.0, 119.0, 178.0, 122.0, 180.0, 184.0, 244.0, 121.0, 186.0, 187.0, 252.0, 188.0, 244.0, 250.0, 316.0, 58.0, 118.0, 122.0, 186.0, 121.0, 179.0, 178.0, 239.0, 118.0, 176.0, 175.0, 236.0, 181.0, 241.0, 246.0, 310.0, 119.0, 180.0, 183.0]\n",
      "resulutssss:  {'list_metricDPError_leaf': [4.0, 8.0, 9.0, 9.0, 11.0, 11.0, 12.0, 13.0, 13.0, 13.0, 15.0, 15.0, 15.0, 17.0, 18.0, 19.0, 18.0, 17.0, 18.0, 18.0, 18.0, 16.0, 15.0, 15.0, 14.0, 14.0, 17.0, 18.0, 21.0, 19.0, 20.0, 19.0, 20.0, 20.0, 21.0, 20.0, 19.0, 21.0, 23.0, 22.0, 21.0, 19.0, 20.0, 19.0, 20.0, 21.0, 20.0, 21.0, 21.0, 21.0], 'list_metricDPStoreError_leaf': [2.0, 4.0, 4.0, 5.0, 7.0, 8.0, 9.0, 9.0, 10.0, 10.0, 12.0, 12.0, 12.0, 13.0, 13.0, 13.0, 14.0, 14.0, 14.0, 15.0, 15.0, 15.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 18.0, 18.0, 19.0, 19.0, 19.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 24.0, 25.0], 'list_metricTTStoreError_leaf': [2.0, 6.0, 6.0, 6.0, 5.0, 8.0, 9.0, 10.0, 10.0, 8.0, 9.0, 11.0, 13.0, 15.0, 16.0, 16.0, 18.0, 18.0, 17.0, 17.0, 17.0, 15.0, 16.0, 16.0, 17.0, 18.0, 18.0, 18.0, 20.0, 16.0, 18.0, 20.0, 19.0, 21.0, 22.0, 21.0, 22.0, 24.0, 24.0, 25.0, 23.0, 21.0, 21.0, 21.0, 23.0, 24.0, 23.0, 22.0, 24.0, 21.0], 'list_runTimeDPSort_leaf': [56553.0, 57390.0, 58371.0, 59186.0, 59988.0, 60665.0, 61598.0, 62463.0, 63387.0, 64214.0, 64842.0, 65687.0, 66662.0, 66806.0, 66878.0, 66907.0, 66907.0, 67036.0, 67051.0, 66950.0, 66892.0, 66850.0, 66749.0, 66748.0, 66792.0, 66850.0, 66850.0, 66850.0, 66836.0, 66893.0, 66605.0, 66735.0, 66878.0, 66749.0, 66821.0, 66936.0, 66835.0, 66893.0, 66994.0, 66994.0, 66994.0, 66793.0, 66620.0, 66635.0, 66678.0, 66822.0, 66865.0, 66764.0, 66634.0, 66778.0], 'list_dummyRecordNumCache_leaf': [10.0, 20.0, 32.0, 43.0, 53.0, 64.0, 75.0, 87.0, 98.0, 110.0, 120.0, 132.0, 144.0, 143.0, 143.0, 143.0, 142.0, 142.0, 142.0, 141.0, 141.0, 141.0, 140.0, 140.0, 140.0, 140.0, 139.0, 139.0, 138.0, 138.0, 137.0, 137.0, 137.0, 136.0, 136.0, 136.0, 136.0, 135.0, 135.0, 135.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 133.0, 133.0, 132.0, 131.0], 'list_metricDPError_treeD': [15.0, 19.0, 41.0, 15.0, 31.0, 35.0, 38.0, 14.0, 25.0, 25.0, 36.0, 17.0, 26.0, 28.0, 31.0, 20.0, 34.0, 22.0, 24.0, 27.0, 37.0, 35.0, 46.0, 32.0, 37.0, 43.0, 54.0, 39.0, 46.0, 49.0, 54.0, 20.0, 43.0, 27.0, 31.0, 21.0, 30.0, 25.0, 29.0, 30.0, 39.0, 39.0, 37.0, 36.0, 43.0, 43.0, 52.0, 31.0, 44.0, 39.0], 'list_metricDPStoreError_treeD': [7.0, 5.0, 23.0, 9.0, 26.0, 29.0, 37.0, 13.0, 22.0, 21.0, 34.0, 17.0, 24.0, 28.0, 31.0, 15.0, 25.0, 23.0, 26.0, 23.0, 28.0, 26.0, 43.0, 26.0, 33.0, 29.0, 41.0, 29.0, 34.0, 36.0, 40.0, 10.0, 33.0, 20.0, 23.0, 12.0, 21.0, 16.0, 20.0, 14.0, 20.0, 16.0, 20.0, 18.0, 22.0, 24.0, 26.0, 13.0, 16.0, 15.0], 'list_metricTTStoreError_treeD': [8.0, 13.0, 18.0, 6.0, 10.0, 11.0, 16.0, 3.0, 12.0, 12.0, 15.0, 8.0, 19.0, 11.0, 16.0, 7.0, 14.0, 12.0, 19.0, 12.0, 18.0, 17.0, 17.0, 12.0, 15.0, 26.0, 23.0, 26.0, 25.0, 26.0, 34.0, 13.0, 21.0, 18.0, 25.0, 19.0, 20.0, 25.0, 26.0, 24.0, 30.0, 36.0, 41.0, 32.0, 34.0, 34.0, 43.0, 28.0, 38.0, 37.0], 'list_runTimeDPSort_treeD': [60481.0, 66777.0, 65874.0, 79141.0, 65101.0, 70273.0, 68926.0, 90555.0, 64600.0, 69547.0, 69548.0, 80283.0, 69576.0, 75747.0, 73973.0, 104308.0, 64757.0, 69808.0, 69404.0, 81399.0, 69461.0, 75324.0, 74502.0, 95495.0, 69260.0, 74091.0, 74912.0, 85305.0, 74929.0, 80005.0, 79488.0, 117102.0, 65531.0, 70026.0, 70055.0, 81771.0, 70722.0, 75397.0, 75807.0, 93994.0, 70941.0, 76295.0, 76677.0, 88511.0, 76190.0, 81566.0, 80924.0, 109669.0, 71303.0, 77117.0], 'list_dummyRecordNumCache_treeD': [61.0, 63.0, 113.0, 59.0, 110.0, 107.0, 167.0, 55.0, 114.0, 115.0, 170.0, 119.0, 180.0, 176.0, 241.0, 53.0, 111.0, 113.0, 178.0, 113.0, 176.0, 178.0, 229.0, 110.0, 171.0, 175.0, 231.0, 175.0, 238.0, 236.0, 300.0, 58.0, 103.0, 116.0, 181.0, 124.0, 183.0, 188.0, 252.0, 122.0, 184.0, 188.0, 252.0, 186.0, 250.0, 248.0, 314.0, 123.0, 188.0, 189.0], 'list_metricDPError_treeA': [24.0, 26.0, 26.0, 19.0, 32.0, 30.0, 36.0, 18.0, 33.0, 32.0, 32.0, 24.0, 41.0, 37.0, 52.0, 14.0, 26.0, 25.0, 31.0, 25.0, 47.0, 39.0, 50.0, 31.0, 38.0, 34.0, 36.0, 38.0, 50.0, 42.0, 47.0, 20.0, 28.0, 27.0, 35.0, 25.0, 41.0, 37.0, 45.0, 27.0, 36.0, 40.0, 44.0, 35.0, 41.0, 38.0, 48.0, 25.0, 28.0, 28.0], 'list_metricDPStoreError_treeA': [9.0, 12.0, 18.0, 12.0, 23.0, 20.0, 34.0, 10.0, 25.0, 26.0, 33.0, 16.0, 34.0, 28.0, 38.0, 8.0, 19.0, 17.0, 26.0, 14.0, 24.0, 20.0, 28.0, 15.0, 18.0, 17.0, 20.0, 16.0, 28.0, 22.0, 24.0, 10.0, 18.0, 14.0, 18.0, 15.0, 25.0, 26.0, 33.0, 18.0, 28.0, 29.0, 36.0, 23.0, 31.0, 26.0, 30.0, 17.0, 24.0, 21.0], 'list_metricTTStoreError_treeA': [15.0, 13.0, 13.0, 7.0, 15.0, 18.0, 9.0, 8.0, 11.0, 8.0, 14.0, 13.0, 10.0, 17.0, 32.0, 7.0, 13.0, 13.0, 20.0, 17.0, 31.0, 27.0, 36.0, 24.0, 31.0, 30.0, 27.0, 31.0, 30.0, 32.0, 40.0, 10.0, 16.0, 18.0, 29.0, 16.0, 22.0, 17.0, 19.0, 16.0, 19.0, 23.0, 25.0, 23.0, 27.0, 27.0, 36.0, 19.0, 22.0, 20.0], 'list_runTimeDPSort_treeA': [60481.0, 137073.0, 65375.0, 319907.0, 64930.0, 142196.0, 70040.0, 731985.0, 65172.0, 142474.0, 68926.0, 326122.0, 69968.0, 147960.0, 74370.0, 1660325.0, 65229.0, 142540.0, 69896.0, 326196.0, 70475.0, 148538.0, 75662.0, 739155.0, 70881.0, 149001.0, 76174.0, 333604.0, 76291.0, 155145.0, 80970.0, 3745900.0, 65272.0, 142590.0, 70505.0, 326253.0, 70330.0, 148373.0, 74547.0, 739219.0, 70069.0, 148076.0, 74705.0, 332544.0, 75175.0, 153880.0, 80271.0, 1668512.0, 70345.0, 148390.0], 'list_dummyRecordNumCache_treeA': [59.0, 56.0, 118.0, 56.0, 113.0, 116.0, 170.0, 58.0, 111.0, 110.0, 171.0, 120.0, 170.0, 176.0, 234.0, 60.0, 117.0, 119.0, 178.0, 122.0, 180.0, 184.0, 244.0, 121.0, 186.0, 187.0, 252.0, 188.0, 244.0, 250.0, 316.0, 58.0, 118.0, 122.0, 186.0, 121.0, 179.0, 178.0, 239.0, 118.0, 176.0, 175.0, 236.0, 181.0, 241.0, 246.0, 310.0, 119.0, 180.0, 183.0]}\n"
     ]
    }
   ],
   "source": [
    "#inputs: \n",
    "T_list = [50]\n",
    "epsAll_list = [1]\n",
    "numReal_list = [1000]\n",
    "runNum = 5\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for T in T_list:\n",
    "    for epsAll in epsAll_list:\n",
    "        for numReal in numReal_list:\n",
    "            \n",
    "            list_metricDPError_leaf = [None]*runNum\n",
    "            list_metricDPStoreError_leaf = [None]*runNum\n",
    "            list_metricTTStoreError_leaf = [None]*runNum\n",
    "            list_runTimeDPSort_leaf = [None]*runNum\n",
    "            list_dummyRecordNumCache_leaf = [None]*runNum\n",
    "            for i in range(runNum):\n",
    "                metricDPError_leaf, metricDPStoreError_leaf, metricTTStoreError_leaf, runTimeDPSort_leaf, dummyRecordNumCache_leaf = metrics(\"leaf\", T, epsAll, numReal, None)\n",
    "                leaf_end_time = time.time()\n",
    "                list_metricDPError_leaf[i] = metricDPError_leaf\n",
    "                list_metricDPStoreError_leaf[i] = metricDPStoreError_leaf\n",
    "                list_metricTTStoreError_leaf[i] = metricTTStoreError_leaf\n",
    "                list_runTimeDPSort_leaf[i] = runTimeDPSort_leaf\n",
    "                list_dummyRecordNumCache_leaf[i] = dummyRecordNumCache_leaf\n",
    "            print(\"leaf***************\")\n",
    "            print(\"--- %s seconds ---\" % (leaf_end_time - start_time))\n",
    "\n",
    "            mean_metricDPError_leaf = np.round(np.mean(list_metricDPError_leaf, axis = 0))\n",
    "            mean_metricDPStoreError_leaf = np.round(np.mean(list_metricDPStoreError_leaf, axis = 0))\n",
    "            mean_metricTTStoreError_leaf = np.round(np.mean(list_metricTTStoreError_leaf, axis = 0))\n",
    "            mean_runTimeDPSort_leaf = np.round(np.mean(list_runTimeDPSort_leaf, axis = 0))\n",
    "            mean_dummyRecordNumCache_leaf = np.round(np.mean(list_dummyRecordNumCache_leaf, axis = 0))\n",
    "            \n",
    "\n",
    "\n",
    "            list_metricDPError_treeD = [None]*runNum\n",
    "            list_metricDPStoreError_treeD = [None]*runNum\n",
    "            list_metricTTStoreError_treeD = [None]*runNum\n",
    "            list_runTimeDPSort_treeD = [None]*runNum\n",
    "            list_dummyRecordNumCache_treeD = [None]*runNum\n",
    "            for i in range(runNum):\n",
    "                metricDPError_treeD, metricDPStoreError_treeD, metricTTStoreError_treeD, runTimeDPSort_treeD, dummyRecordNumCache_treeD = metrics(\"tree\", T, epsAll, numReal, 2)\n",
    "                treeD_end_time = time.time()\n",
    "                list_metricDPError_treeD[i] = metricDPError_treeD\n",
    "                list_metricDPStoreError_treeD[i] = metricDPStoreError_treeD\n",
    "                list_metricTTStoreError_treeD[i] = metricTTStoreError_treeD\n",
    "                list_runTimeDPSort_treeD[i] = runTimeDPSort_treeD\n",
    "                list_dummyRecordNumCache_treeD[i] = dummyRecordNumCache_treeD\n",
    "            print(\"treeD***************\")\n",
    "            print(\"--- %s seconds ---\" % (treeD_end_time - start_time))\n",
    "            mean_metricDPError_treeD = np.round(np.mean(list_metricDPError_treeD, axis = 0))\n",
    "            mean_metricDPStoreError_treeD = np.round(np.mean(list_metricDPStoreError_treeD, axis = 0))\n",
    "            mean_metricTTStoreError_treeD = np.round(np.mean(list_metricTTStoreError_treeD, axis = 0))\n",
    "            mean_runTimeDPSort_treeD = np.round(np.mean(list_runTimeDPSort_treeD, axis = 0))\n",
    "            mean_dummyRecordNumCache_treeD = np.round(np.mean(list_dummyRecordNumCache_treeD, axis = 0))\n",
    "\n",
    "            list_metricDPError_treeA = [None]*runNum\n",
    "            list_metricDPStoreError_treeA = [None]*runNum\n",
    "            list_metricTTStoreError_treeA = [None]*runNum\n",
    "            list_runTimeDPSort_treeA = [None]*runNum\n",
    "            list_dummyRecordNumCache_treeA = [None]*runNum\n",
    "            for i in range(runNum):\n",
    "                metricDPError_treeA, metricDPStoreError_treeA, metricTTStoreError_treeA, runTimeDPSort_treeA, dummyRecordNumCache_treeA = metrics(\"tree\", T, epsAll, numReal, 0)\n",
    "                treeA_end_time = time.time()\n",
    "                list_metricDPError_treeA[i] = metricDPError_treeA\n",
    "                list_metricDPStoreError_treeA[i] = metricDPStoreError_treeA\n",
    "                list_metricTTStoreError_treeA[i] = metricTTStoreError_treeA\n",
    "                list_runTimeDPSort_treeA[i] = runTimeDPSort_treeA\n",
    "                list_dummyRecordNumCache_treeA[i] = dummyRecordNumCache_treeA\n",
    "            print(\"treeA***************\")\n",
    "            print(\"--- %s seconds ---\" % (treeA_end_time - start_time))\n",
    "            mean_metricDPError_treeA = np.round(np.mean(list_metricDPError_treeA, axis = 0))\n",
    "            mean_metricDPStoreError_treeA = np.round(np.mean(list_metricDPStoreError_treeA, axis = 0))\n",
    "            mean_metricTTStoreError_treeA = np.round(np.mean(list_metricTTStoreError_treeA, axis = 0))\n",
    "            mean_runTimeDPSort_treeA = np.round(np.mean(list_runTimeDPSort_treeA, axis = 0))\n",
    "            mean_dummyRecordNumCache_treeA = np.round(np.mean(list_dummyRecordNumCache_treeA, axis = 0))\n",
    "\n",
    "\n",
    "            fileName = \"newResultsPY/T:\"+str(T)+\",eps:\"+str(epsAll)+\",N:\"+str(numReal)+\".json\"\n",
    "\n",
    "            print(\"resulutssss D: \", mean_dummyRecordNumCache_treeD.tolist())\n",
    "            \n",
    "            print(\"resulutssss A: \", mean_dummyRecordNumCache_treeA.tolist())\n",
    "            \n",
    "            with open(fileName, 'w') as f:\n",
    "                entry = {}\n",
    "                \n",
    "                entry['list_metricDPError_leaf'] = mean_metricDPError_leaf.tolist()\n",
    "                entry['list_metricDPStoreError_leaf'] = mean_metricDPStoreError_leaf.tolist()\n",
    "                entry['list_metricTTStoreError_leaf'] = mean_metricTTStoreError_leaf.tolist()\n",
    "                entry['list_runTimeDPSort_leaf'] = mean_runTimeDPSort_leaf.tolist()\n",
    "                entry['list_dummyRecordNumCache_leaf'] = mean_dummyRecordNumCache_leaf.tolist()\n",
    "                \n",
    "                \n",
    "                entry['list_metricDPError_treeD'] = mean_metricDPError_treeD.tolist()\n",
    "                entry['list_metricDPStoreError_treeD'] = mean_metricDPStoreError_treeD.tolist()\n",
    "                entry['list_metricTTStoreError_treeD'] = mean_metricTTStoreError_treeD.tolist()\n",
    "                entry['list_runTimeDPSort_treeD'] = mean_runTimeDPSort_treeD.tolist()\n",
    "                entry['list_dummyRecordNumCache_treeD'] = mean_dummyRecordNumCache_treeD.tolist()\n",
    "                \n",
    "                entry['list_metricDPError_treeA'] = mean_metricDPError_treeA.tolist()\n",
    "                entry['list_metricDPStoreError_treeA'] = mean_metricDPStoreError_treeA.tolist()\n",
    "                entry['list_metricTTStoreError_treeA'] = mean_metricTTStoreError_treeA.tolist()\n",
    "                entry['list_runTimeDPSort_treeA'] = mean_runTimeDPSort_treeA.tolist()\n",
    "                entry['list_dummyRecordNumCache_treeA'] = mean_dummyRecordNumCache_treeA.tolist()\n",
    "             \n",
    "                print(\"resulutssss: \", entry)\n",
    "              #  json.dump(entry, f, ensure_ascii=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resulutssss:  [59.0, 56.0, 118.0, 56.0, 113.0, 116.0, 170.0, 58.0, 111.0, 110.0, 171.0, 120.0, 170.0, 176.0, 234.0, 60.0, 117.0, 119.0, 178.0, 122.0, 180.0, 184.0, 244.0, 121.0, 186.0, 187.0, 252.0, 188.0, 244.0, 250.0, 316.0, 58.0, 118.0, 122.0, 186.0, 121.0, 179.0, 178.0, 239.0, 118.0, 176.0, 175.0, 236.0, 181.0, 241.0, 246.0, 310.0, 119.0, 180.0, 183.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"resulutssss: \", entry[\"list_dummyRecordNumCache_treeA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-60e33edda3e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnumReal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmetricDPError_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetricDPStoreError_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetricTTStoreError_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunTimeDPSort_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummyRecordNumCache_leaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"leaf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsAll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumReal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mleaf_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"leaf***************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-e1f9353c8263>\u001b[0m in \u001b[0;36mmetrics\u001b[0;34m(treeorLeaf, T, epsAll, numReal, sortOption)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mdpHistsLeaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDPTimeLeaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrueHists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumBins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtrueRecordNum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunTimeDPSort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummyRecordNumCache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msortLeaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumBins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpHistsLeaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginalData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginalDummyMarkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mDPCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-7400d8b6b210>\u001b[0m in \u001b[0;36msortLeaf\u001b[0;34m(T, numBins, dpHists, originalData, originalDummyMarkers)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mjStr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m','\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mtrueR\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcomputeTrueRecords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpHists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjStr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmainData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjStr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mtrueRecordNum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrueR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7868720b3868>\u001b[0m in \u001b[0;36mcomputeTrueRecords\u001b[0;34m(dpHist, dpStore)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpHistPrefix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpHistPrefix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpStore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#dpStorePublic[j]: 1122334455\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0mtrueR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrueR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "T = 1000\n",
    "epsAll = 10\n",
    "numReal = 1000\n",
    "start_time = time.time()\n",
    "metricDPError_leaf, metricDPStoreError_leaf, metricTTStoreError_leaf, runTimeDPSort_leaf, dummyRecordNumCache_leaf = metrics(\"leaf\", T, epsAll, numReal, None)\n",
    "leaf_end_time = time.time()\n",
    "print(\"leaf***************\")\n",
    "print(\"--- %s seconds ---\" % (leaf_end_time - start_time))\n",
    "print(metricDPError_leaf)\n",
    "print(metricDPStoreError_leaf)\n",
    "print(metricTTStoreError_leaf)\n",
    "print(runTimeDPSort_leaf)\n",
    "print(dummyRecordNumCache_leaf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricDPError_treeA, metricDPStoreError_treeA, metricTTStoreError_treeA, runTimeDPSort_treeA，dummyRecordNumCache_treeA = metrics(\"tree\", T, epsAll, numReal, 0)\n",
    "treeA_end_time = time.time()\n",
    "print(\"treeA***************\")\n",
    "print(\"--- %s seconds ---\" % (treeA_end_time - start_time))\n",
    "print(\"metricDPError_treeA: \", metricDPError_treeA)\n",
    "print(\"metricDPStoreError_treeA: \", metricDPStoreError_treeA)\n",
    "print(\"metricTTStoreError_treeA: \", metricTTStoreError_treeA)\n",
    "print(runTimeDPSort_treeA)\n",
    "print(dummyRecordNumCache_treeA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = math.log(T, 2)\n",
    "eps = epsAll/level \n",
    "t = math.log((1/0.01), math.e)\n",
    "d = math.ceil((1/eps) * t)\n",
    "numDummy = math.ceil((1/eps) * t) * numBins\n",
    "print(eps)\n",
    "print(numDummy)\n",
    "print(d)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
